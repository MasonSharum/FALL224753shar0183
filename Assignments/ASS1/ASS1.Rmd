---
title: "Assignment 1"
author: "Mason Sharum"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

I completed 15/15 questions in this assignment.

# Question 1

Below is the table of grading weights for the course.

| Group            | Amount | Total Weight |
| ---------------  | -----: | -----------: |
| Assignments      | 4      | 15%          |
| Laboratories     | 16     | 10%          |
| Projects         | 2      | 10%          |
| In Class Quizzes | TBD    | 10%          |
| Chapter Quizzes  | TBD    | 5%           |
| Mid-Term Exam    | 1      | 20%          |
| Final Exam       | 1      | 30%          |

The grading scale is as follows: A (100-90) B(89-80) C(79-60) D(59-50) F(<50), and there will be no curves.


# Question 2

```{r}
ddt <- read.csv("DDT.csv")
head(ddt)

ddt$MILE = factor(ddt$MILE)
```

## (a)

```{r}
with(ddt, coplot(LENGTH ~ WEIGHT | RIVER * SPECIES, ddt, col = MILE))
```

## (b)

The length and weight of catfish found in the FCM, LCM, and SCM rivers increase together in a positive correlation.

## (c)

Line A is a function call that creates a factor object of the MILE variable, meaning it makes a vector of the measurements from MILE after sorting them into categories.

## (d)

Line B is a function call that returns the number of unique values in the previously made vector. For instance if the vector was [1, 1, 2, 3, 3], it would return 3 since there are three unique numbers.

## (e)

The top six plots are empty because there are no fish that are either LMBASS or SMBUFFALO that were caught in the FCM, LCM, or SCM rivers.

## (f)

```{r}
cat = subset(ddt, RIVER == "FCM" & SPECIES == "CCATFISH",)
mean(cat$DDT)
```

# Question 3

## (a)

Length of the maximum span (feet) is a quantitative variable.

## (b)

Number of vehicle lanes is a quantitative variable.

## (c)

TOll bridge (yes or no) is a qualitative variable.

## (d)

Average daily traffic is a quantitative variable.

## (e)

Condition of deck (good, fair, poor) is a qualitative variable.

## (f)

Bypass or detour length (miles) is a quantitative variable.

## (g)

Route type (interstate, U.S., state, county, or city) is a qualitative variable.

# Question 4

## (a)

The four random sampling designs are as follows: simple random sampling, stratified random sampling, cluster sampling, and systematic sampling.

## (b)

Simple random sampling happens when n experimental units are selected from the population in such a way that every different sample of size n has an equal chance of selection.

Stratified random sampling happens when the population is separated into different strata based off of certain characteristics of the experimental units. These strata are then randomly sampled from.

Cluster sampling happens when a group(or cluster) is selected from within the population and then data is taken about every unit in the cluster.

Systematic sampling happens when every kth experimental unit is selected from a list of all experimental units.

# Question 5

```{r}
mtbe <- read.csv("MTBE.csv")
head(mtbe)

ind = sample(1:223, 5, replace = FALSE)
mtbe[ind,]
```

## (a)

### (i)

```{r}
mtbeo = na.omit(mtbe)
```

### (ii)

```{r}
depth = mtbeo[mtbeo$Aquifier == "Bedrock",]$Depth
sd(depth)
```

# Question 6

```{r}
eq <- read.csv("EARTHQUAKE.csv")
head(eq)

ind = sample(1:2929, 30, replace = FALSE)
eq[ind,]
```

## (a)

### (i)

```{r}
plot(ts(eq$MAG))

median(eq$MAGNITUDE)
```

# Question 7

## (a)

The data was collected with a stratified sample.

## (b)

The population is all of the fish in the Tennessee River.

## (c)

The qualitative variables are location and species. Location was divided into river and mile.

# Question 8

## (a)

A bar graph is used to describe the data.

## (b)

The variable measured for each of the 106 robot designs was type of robotic limbs.

## (c)

The current most used design of robot is legs only.

## (d)

```{r}
limb_freq = c(15, 8, 63, 20)
limb_labels = c("None", "Both", "Legs", "Wheels")
rel_freq = as.data.frame(matrix(data = limb_freq/sum(limb_freq), nrow = 4, ncol = 1), row.names = limb_labels)
rel_freq
```

## (e)

```{r}
source("pareto.r")
l = rep(limb_labels, limb_freq)
pareto(l)
```

# Question 9

## (a)

```{r}
nums = c(32, 6, 12)
labs = c("Windows", "Explorer", "Office")
pie(nums, labels = labs, main = "Microsoft Products with Security Issues")
```

## (b)

```{r}
MSFreq = c(6, 8, 22, 3, 11)
MSLabel = c("DoS", "Info Leak", "RCE", "Spoofing", "Elevation")
MS = rep(MSLabel, MSFreq)
pareto(MS)
```

Based on this diagram, I would say they should focus on fixing the Remote Code Execution problem, as that seems to be the most commonly used exploit.

# Question 10

```{r}
swd = read.csv("SWDEFECTS.csv")
head(swd)

library(plotrix)
tab = table(swd$defect)
rtab = tab/sum(tab)
round(rtab, 2)
pie3D(rtab, labels = list("OK", "Defective"), main = "Pie Plot of SWD")
```

Based off of the pie chart it is easy to see that there is a high likelihood of defective software code.

# Question 11

## (a)

| Class | Class Interval    | Data Tabulation                                                     | Frequency | Relative Frequency |
| :---: | :-------------:   | :-----------------------------------------------------------------  | :-------: | :----------------: |
| 1     | [8.0000,8.2900]   | 8.05                                                                | 1         | 0.0333             |
| 2     | (8.2900,8.5800]   | -                                                                   | 0         | 0.0000             |
| 3     | (8.5800,8.8700]   | 8.72,8.72,8.80                                                      | 3         | 0.1000             |
| 4     | (8.8700,9.1600]   | -                                                                   | 0         | 0.0000             |
| 5     | (9.1600,9.4500]   | -                                                                   | 0         | 0.0000             |
| 6     | (9.4500,9.7400]   | 9.55,9.70,9.73                                                      | 3         | 0.1000             |
| 7     | (9.7400,10.0200]  | 9.80,9.80,9.84,9.84,9.87,9.87,9.95,9.97,9.98,9.98,10.00,10.01,10.02 | 13        | 0.4333             |
| 8     | (10.0200,10.3100] | 10.03,10.05,10.05,10.12,10.15,10.15,10.26,10.26,10.29               | 9         | 0.3000             |
| 9     | (10.3100,10.6000] | 10.55                                                               | 1         | 0.0333             |
| Total | -                 | -                                                                   | 30        | 1                  |

```{r}
volt <- read.csv("VOLTAGE.csv")
head(volt)
old = volt[volt$LOCATION == "OLD",]
new = volt[volt$LOCATION == "NEW",]
vto = old$VOLTAGE
vto
max(vto)
min(vto)
lept = min(vto) - 0.05
rept = max(vto) + 0.05
rnge = rept - lept
inc = rnge/9
inc
cl = seq(lept, rept,by = inc)
cl
cuts = cut(vto,breaks = cl)
old.tab = table(cuts)
barplot(old.tab / sum(old.tab), space = 0, main = "Relative Frequency(OLD)", las = 2)
```

## (b)

```{r}
volt <- read.csv("VOLTAGE.csv")
head(volt)
old = volt[volt$LOCATION == "OLD",]
new = volt[volt$LOCATION == "NEW",]
stem(x = old$VOLTAGE)
```

Both graphs are equally informative about where most of the voltage readings lie. The stem and leaf display gives you exact numbers for how many are in each section though so that is a bit more descriptive but both are able to tell you which area has the most data points.

## (c)

```{r}
vtn = new$VOLTAGE
vtn
max(vtn)
min(vtn)
lept = min(vtn) - 0.05
rept = max(vtn) + 0.05
rnge = rept - lept
inc = rnge/9
inc
cl = seq(lept, rept,by = inc)
cl
cuts = cut(vtn,breaks = cl)
new.tab = table(cuts)
barplot(new.tab/sum(new.tab), space = 0, main = "Frequency Histogram(NEW)", las = 2)
```

## (d)

The new location has a lot more voltages that fall below the cutoff point of 9.2, while the old location has a lot less. This shows that the new location is not yet as good as the previous location and that they should probably not yet move over production.

## (e)

### OLD

```{r}
source("getmode.R")
mean(old$VOLTAGE)
median(old$VOLTAGE)
getmode(old$VOLTAGE)
```

The average reading is about 9.8 and the middle value is 9.975, while the most common value is 9.98. I would say that the mean is the best indicator of central tendency in this case, because the distribution is close to normal so the mean will be centralized.

### NEW

```{r}
mean(new$VOLTAGE)
median(new$VOLTAGE)
getmode(new$VOLTAGE)
```

The average reading is about 9.4 and the middle value is 9.455, while the most common value is 8.82. I would say that the mean is the best indicator of central tendency in this case, because the distribution is close to normal so the mean will be centralized.

## (f)

```{r}
(10.5 - mean(old$VOLTAGE))/sd(old$VOLTAGE)
```

## (g)

```{r}
(10.5 - mean(new$VOLTAGE))/sd(new$VOLTAGE)
```

## (h)

The reading of 10.5 is more likely to occur at the old location since it has a lower z-score at the old location meaning it is closer to the mean and therefore more likely to occur.

## (i)

```{r}
boxplot(old$VOLTAGE, horizontal = T)
```

There appear to be outliers in the old location.

## (j)

```{r}
old[abs((old$VOLTAGE-mean(old$VOLTAGE))/sd(old$VOLTAGE)) > 3,]
```

## (k)

```{r}
boxplot(new$VOLTAGE, horizontal = T)
```

There does not seem to be any outliers based off of this boxplot.

## (l)

```{r}
new[abs((new$VOLTAGE-mean(new$VOLTAGE))/sd(new$VOLTAGE)) > 3,]
```

## (m)

```{r}
boxplot(old$VOLTAGE, new$VOLTAGE, names = c("Old", "New"))
```

# Question 12

```{r}
pipe <- read.csv("ROUGHPIPE.csv")
avg = mean(pipe$R)
stddev = sd(pipe$R)
c(avg - (2*stddev), avg + (2*stddev))
```

This is the range of two standard deviations away from the mean in each direction, which according to the empirical rule will contain approximately 95% of the data since the shape of the data is normal.

# Question 13

## (a)

```{r}
ants = read.csv("GOBIANTS.csv")
head(ants)

mean(ants$AntSpecies)
median(ants$AntSpecies)
getmode(ants$AntSpecies)
```
The mean is the average number of species found. The median is the middle number of species found. The mode is the most common number of species found.

## (b)

I would use the median as the mean is much higher than the median meaning the mean is probably skewed. The mode is 
just the most common number which could be the largest number appearing twice and hundreds of smaller numbers only appearing once. The median is always in the middle of the data, and in this case seems to be the best measure for this.

## (c)

```{r}
step = ants[ants$Site < 6,]
mean(step$PlantCov)
median(step$PlantCov)
getmode(step$PlantCov)
```

## (d)

```{r}
des = ants[ants$Site >= 6,]
mean(des$PlantCov)
median(des$PlantCov)
getmode(des$PlantCov)
```

## (e)

Yes it appears to be different between the two regions, as the Dry Steppe Sites are around 40 and the Gobi Desert sites are lower down around 28.

# Question 14

## (a)

```{r}
gal <- read.csv("GALAXY2.csv")
head(gal)
with(gal, hist(VELOCITY, breaks = 10))
```

## (b)

Yes, there is evidence to support the double cluster theory since there are two separate peaks within the graph.

## (c)

```{r}
A = gal$V[gal$V <= 21000];
B = gal$V[gal$V > 21000];
```

Galaxy A

```{r}
mean(A)
sd(A)
```

Galaxy B

```{r}
mean(B)
sd(B)
```

## (d)

If a galaxy velocity of 20,000 km/s is observed it would likely belong to cluster A, since that value is much closer to galaxy A's mean of 19462.24 than to galaxy B's mean of 22838.47. 

# Question 15

```{r}
library(ggplot2)
ggplot(ddt, aes(x = RIVER, y = LENGTH)) + geom_boxplot(aes(fill = SPECIES)) + ggtitle("Mason Sharum")
```






















